---
title: "Lab 05"
author: "Yuhong Hu"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dtplyr)
library(tidyverse)
library(data.table)
library(lubridate)
```


# Read in data
```{r read-data,cache=TRUE}
if (!file.exists("/Users/rain/Desktop/PhD course/pm 566/pm566-fall2022-labs/lab04/met_all.gz"))
  download.file(
    url = "https://raw.githubusercontent.com/USCbiostats/data-science-data/master/02_met/met_all.gz",
    destfile = "met_all.gz",
    method   = "libcurl",
    timeout  = 60
    )
met <- data.table::fread("/Users/rain/Desktop/PhD course/pm 566/pm566-fall2022-labs/lab04/met_all.gz")


# Prepare the data
## Remove temperatures less than -17C and change elev 9999 to NA

met <- met[temp > -17][elev == 9999.0,elev := NA]
```


```{r station}
# Download the data
stations <- fread("ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv")
stations[, USAF := as.integer(USAF)]

# Dealing with NAs and 999999
stations[, USAF   := fifelse(USAF == 999999, NA_integer_, USAF)]
stations[, CTRY   := fifelse(CTRY == "", NA_character_, CTRY)]
stations[, STATE  := fifelse(STATE == "", NA_character_, STATE)]

# Selecting the three relevant columns, and keeping unique records
stations <- unique(stations[, list(USAF, CTRY, STATE)])

# Dropping NAs
stations <- stations[!is.na(USAF)]

# Removing duplicates
stations[, n := 1:.N, by = .(USAF)]
stations <- stations[n == 1,][, n := NULL]
```

merge data with stations
```{r merge}
met <- merge(
  # Data
  x     = met,      
  y     = stations, 
  # List of variables to match
  by.x  = "USAFID",
  by.y  = "USAF", 
  # Which obs to keep?
  all.x = TRUE,      
  all.y = FALSE
  ) 

```


# Question 1: Representative station for the US
```{r}
# Compute mean temperature, wind speed, and ap for each weather station, and pick the weather station with the average value closest to th median for the US.

station_average <-
  met[, .(temp = mean(temp,na.rm=T),
          windsp=mean(wind.sp,na.rm=T),
          atm.press=mean(atm.press,na.rm=T)),by=USAFID]

# now get the median value for each variable

statmedian <-
  met[,.(
  temp50=median(temp,na.rm = T),
  windsp50=median(wind.sp,na.rm=T),
  atmpress50=median(atm.press,na.rm=T)
)]

# A helpful function 'which.min()' we might want to use
station_average[, temp_dist50:=abs(temp-statmedian$temp50)][order(temp_dist50)]
station_average[which.min(temp_dist50)]
```

# Question 2: Representative station per state
Just like the previous question, you are asked to identify what is the most representative, the median, station per state. This time, instead of looking at one variable at a time, look at the euclidean distance. If multiple stations show in the median, select the one located at the lowest latitude.
```{r}
station_average <-
  met[, .(temp = mean(temp,na.rm=T),
          windsp=mean(wind.sp,na.rm=T),
          atm.press=mean(atm.press,na.rm=T)),by=.(USAFID,STATE)]

# now get the median value for each variable


state_median <- station_average[,.(temp50=median(temp,na.rm=T),
                   wind.sp50=median(windsp,na.rm=T)),by=STATE]

# merge median and average

station_average <- merge(
  x=station_average,
  y=state_median,
  by.x = 'STATE',
  by.y= 'STATE',
  all.x=TRUE,
  all.y=FALSE
)

# find the smallest distance, A helpful function 'which.min()' we might want to use
station_average[,temp_dist_state50 := temp - temp50]
station_average[,windsp_dist50 := windsp - wind.sp50]

station_average[,eucdist :=temp_dist_state50^2 +windsp_dist50^2 ]


repstation <- station_average[,.(eucdist=min(eucdist,na.rm=TRUE)),by=STATE]

# merge the repstation with the station_average
test <- merge(x=station_average,
  y=repstation,
  by.x = c('eucdist','STATE'),
  by.y= c('eucdist','STATE'),
  all.x=FALSE,
  all.y=TRUE
)

dim(test)

```


